{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spacy_NLP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John260260/Deep_Learning/blob/main/Spacy_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANPLEkRKjDwM"
      },
      "source": [
        "# BASICS OF spaCy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6dLhRTtjIgf"
      },
      "source": [
        "# loading spacy library\n",
        "import spacy\n",
        "nlp=spacy.load('en') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5gBDID7jSu7"
      },
      "source": [
        "## Reading a Text Document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHhqw3eUjQDv",
        "outputId": "7ff17dc3-5166-45d9-f5b2-2ed9963c50a2"
      },
      "source": [
        "doc1=nlp(\"We are learning spaCy\")\n",
        "doc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "We are learning spaCy"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "7srlld_RjV_g",
        "outputId": "96379044-a8b9-40c7-d58f-e69333bdeafa"
      },
      "source": [
        "## Reading a File\n",
        "myfile=open(\"/content/drive/MyDrive/Colab Notebooks/reason for hope.txt\").read()\n",
        "myfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Jane Goodall - Author\\nJudy- sis\\nGombe- place of research\\nDanny- grandmother\\nVanne- Mother\\nBach(Music:Toccat,Fugue)- musician \\nProspagnosia:(m) probs in face recognition\\nDr.Oliver Sacks- Neurologist\\nChristine Temple (Author): Developmental memory imparitment\\nDr. Louis Leakey: Mentor Guide\\nJubilee: 1st gorilla to be born in London\\nMortimier Mort Goodall- dad\\nDanny Nutt- Grand Ma- Dads mom\\nBriches- GrandMOms home, Vannes mom\\nDanny- Maternal Grandmom\\nOlwen/Olly and Audrey- Moms sisters\\nSally and Sussie Cary- best friends\\nSelina Bushel- school owner\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeWmPwXtjaLK",
        "outputId": "c646bf09-53cc-4df6-848b-f0014bf604b1"
      },
      "source": [
        "file1=nlp(myfile)\n",
        "file1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Jane Goodall - Author\n",
              "Judy- sis\n",
              "Gombe- place of research\n",
              "Danny- grandmother\n",
              "Vanne- Mother\n",
              "Bach(Music:Toccat,Fugue)- musician \n",
              "Prospagnosia:(m) probs in face recognition\n",
              "Dr.Oliver Sacks- Neurologist\n",
              "Christine Temple (Author): Developmental memory imparitment\n",
              "Dr. Louis Leakey: Mentor Guide\n",
              "Jubilee: 1st gorilla to be born in London\n",
              "Mortimier Mort Goodall- dad\n",
              "Danny Nutt- Grand Ma- Dads mom\n",
              "Briches- GrandMOms home, Vannes mom\n",
              "Danny- Maternal Grandmom\n",
              "Olwen/Olly and Audrey- Moms sisters\n",
              "Sally and Sussie Cary- best friends\n",
              "Selina Bushel- school owner"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLopC0Okmt--",
        "outputId": "6c5ad684-5b95-4982-8f66-280313f0eac4"
      },
      "source": [
        "for num,sentence in enumerate(file1.sents):\n",
        "  print(f'{num}:{sentence}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:Jane Goodall\n",
            "1:- Author\n",
            "\n",
            "2:Judy- sis\n",
            "\n",
            "3:Gombe- place of research\n",
            "\n",
            "4:Danny- grandmother\n",
            "Vanne-\n",
            "5:Mother\n",
            "\n",
            "6:Bach(Music:\n",
            "7:Toccat,Fugue)- musician \n",
            "\n",
            "8:Prospagnosia:(m) probs in face recognition\n",
            "\n",
            "9:Dr.\n",
            "10:Oliver Sacks-\n",
            "11:Neurologist\n",
            "Christine Temple (Author):\n",
            "12:Developmental memory imparitment\n",
            "\n",
            "13:Dr. Louis Leakey:\n",
            "14:Mentor Guide\n",
            "\n",
            "15:Jubilee:\n",
            "16:1st gorilla to be born in London\n",
            "\n",
            "17:Mortimier Mort Goodall-\n",
            "18:dad\n",
            "\n",
            "19:Danny Nutt-\n",
            "20:Grand\n",
            "21:Ma-\n",
            "22:Dads mom\n",
            "\n",
            "23:Briches-\n",
            "24:GrandMOms home, Vannes mom\n",
            "Danny-\n",
            "25:Maternal Grandmom\n",
            "Olwen/\n",
            "26:Olly and Audrey-\n",
            "27:Moms sisters\n",
            "\n",
            "28:Sally and Sussie Cary-\n",
            "29:best friends\n",
            "Selina Bushel- school owner\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Q6O9r5pdUb",
        "outputId": "c26b275a-4a53-4471-abe2-8aefaf9b4981"
      },
      "source": [
        "doc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "We are learning spaCy"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LBNdKNBp2pG",
        "outputId": "87436648-30df-4ffb-fbe5-b0e053a88d3c"
      },
      "source": [
        "for token in doc1:\n",
        "  print(token.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We\n",
            "are\n",
            "learning\n",
            "spaCy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMTdk_3vp8ng",
        "outputId": "cc28e993-dcc0-411b-934a-8d6740b9e4aa"
      },
      "source": [
        "doc2=nlp('I have 3 coins and 10 rupees note')\n",
        "doc2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "I have 3 coins and 10 rupees note"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b3NE-5dqRtO",
        "outputId": "1da3452b-2262-4a2b-e200-81704c40daa9"
      },
      "source": [
        "## is_alpha property\n",
        "for word in doc2:\n",
        "  print(word.text,word.is_alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I True\n",
            "have True\n",
            "3 False\n",
            "coins True\n",
            "and True\n",
            "10 False\n",
            "rupees True\n",
            "note True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jaN5RhKqlsR",
        "outputId": "c260e688-73ec-44b0-bf81-5f66cdab364a"
      },
      "source": [
        "## is_stop property\n",
        "for word in doc2:\n",
        "  print(word.text,word.is_stop)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I True\n",
            "have True\n",
            "3 False\n",
            "coins False\n",
            "and True\n",
            "10 False\n",
            "rupees False\n",
            "note False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuZYHNSWrJmX",
        "outputId": "50a90a2b-3dc3-44ff-fa78-486df45c4f8f"
      },
      "source": [
        "#shape property\n",
        "for word in doc1:\n",
        "  print(word.text,word.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We 12204527652707022206\n",
            "are 4088098365541558500\n",
            "learning 13110060611322374290\n",
            "spaCy 12543853910902138754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyJZebOjunca"
      },
      "source": [
        "#part of speech tagging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIDj3UUEvYdt"
      },
      "source": [
        "#pos_strategy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnv154MPvcLA",
        "outputId": "7ecffe45-ebc5-4eea-c3d4-088b21af5ce4"
      },
      "source": [
        "for word in doc1:\n",
        "  print(word.text,word.pos_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We PRON\n",
            "are AUX\n",
            "learning VERB\n",
            "spaCy NUM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nucgBpgmvklQ",
        "outputId": "b659532f-c0c7-46e1-97d4-2b34a8dfd724"
      },
      "source": [
        "#tagging\n",
        "for word in doc1:\n",
        "  print(word.text,word.pos_,word.tag_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We PRON PRP\n",
            "are AUX VBP\n",
            "learning VERB VBG\n",
            "spaCy NUM CD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p82pLiRcvsX3",
        "outputId": "4adcf331-3980-4d86-c361-8ab742e827a8"
      },
      "source": [
        "## meaning of pos abbrev.\n",
        "spacy.explain('NN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'noun, singular or mass'"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mEeMvsKGwTUf",
        "outputId": "2777d075-c119-4c8a-95ff-756a126ddd3a"
      },
      "source": [
        "spacy.explain('VBP')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'verb, non-3rd person singular present'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yMP0qWa0w1fR",
        "outputId": "c1611922-10f2-4c42-d268-267e962ae6d6"
      },
      "source": [
        "spacy.explain('NUM')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'numeral'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9Stb4c-wW9r"
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "4QmSTJW3wqqL",
        "outputId": "d1dc61d0-0f48-4420-c02b-363fd16e9b41"
      },
      "source": [
        "displacy.render(doc1,style='dep',jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f0b2e18865cd4fc196c6466af4220469-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">We</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">are</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">spaCy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f0b2e18865cd4fc196c6466af4220469-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f0b2e18865cd4fc196c6466af4220469-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f0b2e18865cd4fc196c6466af4220469-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f0b2e18865cd4fc196c6466af4220469-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f0b2e18865cd4fc196c6466af4220469-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f0b2e18865cd4fc196c6466af4220469-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiDMyJivwuWN"
      },
      "source": [
        "#Lemmatization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFQ8KwfM-fFR"
      },
      "source": [
        "doc3=nlp('playing played player')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSTdgJgF-mxG",
        "outputId": "951d8c4e-ed41-4df3-e163-040ddc40f117"
      },
      "source": [
        "for word in doc3:\n",
        "  print(word.text,word.lemma_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playing play\n",
            "played play\n",
            "player player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP7nR99X-s5h"
      },
      "source": [
        "doc4=nlp('walks walked walking')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hCSzJ8fCZtg",
        "outputId": "e5218978-a345-451b-fa95-6f727d1373df"
      },
      "source": [
        "for word in doc4:\n",
        "  print(word.text,word.lemma_,word.pos_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "walks walk NOUN\n",
            "walked walk VERB\n",
            "walking walk VERB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkKYzwZ9Cj7C"
      },
      "source": [
        "## Named Entity Recognition or Detection\n",
        "\n",
        "doc5=nlp(\"By 2025 , India will grow so much in Technical field and earn more than 5 million dollars\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JidrcEAyC0AU",
        "outputId": "399d76cb-b70d-418e-e565-cdf43937c527"
      },
      "source": [
        "for word in doc5.ents:\n",
        "    print(word.text,word.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025 DATE\n",
            "India GPE\n",
            "more than 5 million dollars MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xtyNUlT1bOAC",
        "outputId": "fd481039-78cd-4ce8-e19d-7bc78be96b00"
      },
      "source": [
        "spacy.explain('GPE')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Countries, cities, states'"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "cPuBwEvgbbtg",
        "outputId": "1e709d98-6e17-4a03-90b3-c6c6d9e29332"
      },
      "source": [
        "displacy.render(doc5,style='ent',jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2025\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " , \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    India\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " will grow so much in Technical field and earn \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    more than 5 million dollars\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hLSXExlbsMI"
      },
      "source": [
        "#semantic similarity\n",
        "word1= nlp('dog')\n",
        "word2= nlp('cat')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9AhQjfgemib",
        "outputId": "53867ddf-acf0-4a52-db03-d55c8666138e"
      },
      "source": [
        "#similarity between words\n",
        "word1.similarity(word2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6549556828973659"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzV1WnAEer5W"
      },
      "source": [
        "doc5=nlp('cat dog fish bird')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhcuqFDje_2E",
        "outputId": "10e0db98-1655-4dee-e869-a79e487ec14b"
      },
      "source": [
        "for w1 in doc5:\n",
        "  for w2 in doc5:\n",
        "    print(w1.text,w2.text),'Similarity:-',(w1.similarity(w2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat cat\n",
            "cat dog\n",
            "cat fish\n",
            "cat bird\n",
            "dog cat\n",
            "dog dog\n",
            "dog fish\n",
            "dog bird\n",
            "fish cat\n",
            "fish dog\n",
            "fish fish\n",
            "fish bird\n",
            "bird cat\n",
            "bird dog\n",
            "bird fish\n",
            "bird bird\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.7/runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  \"__main__\", mod_spec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhvv-41efgNx"
      },
      "source": [
        "#stop words\n",
        "\n",
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAPgNqfKgNvU",
        "outputId": "93160a4e-a5e6-49ea-c98b-c0bf7ea0cd93"
      },
      "source": [
        "print(STOP_WORDS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'again', 'their', 'else', 'wherever', 'us', 'be', 'up', 'bottom', 'since', 'anywhere', 'otherwise', 'across', '’ve', 'really', 'seemed', 'seems', 'herein', 'anyway', 'nowhere', 'behind', 'say', \"'re\", 'of', 'thereupon', 'between', 'even', 'hereby', 'by', 'no', 'mostly', 'empty', 'used', 'cannot', 'before', 'forty', 'my', 'also', '’m', 'many', 'herself', '‘ll', 'moreover', 'four', 'became', 'whether', 'over', 'thereafter', 'put', 'should', 'three', 'would', 'can', 'then', '’ll', 'may', 'sometime', 'third', 'whom', 'might', 'ever', 'still', 'almost', 'those', 'thru', 'her', 'his', 'get', 'had', 'towards', 'whereupon', '’s', 'down', 'few', 're', 'and', 'unless', 'myself', 'only', 'other', 'beyond', 'themselves', 'namely', 'its', 'five', 'most', 'n‘t', 'through', 'eleven', 'more', 'doing', 'without', 'front', 'because', 'must', 'somewhere', \"'ve\", \"'m\", 'they', \"'ll\", 'an', 'keep', 'hereafter', 'seeming', 'elsewhere', 'we', 'either', 'whereafter', 'using', 'during', 'whither', 'although', 'none', 'every', 'while', 'there', 'go', 'nobody', 'both', 'please', 'nevertheless', 'around', 'well', 'perhaps', 'which', 'therefore', 'via', 'back', 'first', 'part', 'amongst', 'he', 'very', 'than', 'twenty', 'itself', 'yourselves', 'latterly', 'except', 'two', 'per', 'under', 'yourself', 'take', 'whereas', 'some', 'sometimes', 'whole', 'whoever', 'at', 'others', 'own', 'latter', '‘ve', 'am', 'the', 'if', 'alone', 'throughout', 'will', 'within', 'above', 'where', 'whatever', 'this', \"n't\", 'is', 'on', '‘d', 'next', 'though', 'name', 'together', 'however', 'quite', 'with', 'among', 'further', 'seem', 'was', 'another', 'were', 'show', 'do', 'nothing', 'ourselves', 'that', 'could', 'see', 'noone', 'someone', 'anyhow', 'side', 'i', 'are', 'what', '’re', 'serious', 'meanwhile', 'whence', 'done', 'move', '’d', 'neither', 'about', 'in', 'always', 'after', 'has', 'how', 'so', 'several', '‘s', 'twelve', 'me', 'often', 'top', 'below', 'rather', 'yours', 'become', 'these', 'yet', 'everything', 'full', 'becoming', 'call', 'never', \"'d\", 'six', 'until', 'toward', 'off', '‘re', 'becomes', 'hundred', 'anything', 'mine', 'least', 'ten', 'here', 'to', 'each', 'various', 'fifty', 'indeed', 'ours', 'already', 'former', 'into', 'something', 'whenever', 'you', 'them', 'being', 'such', 'somehow', 'once', 'your', 'does', 'nine', 'hers', 'give', 'eight', 'as', 'due', 'she', 'one', 'therein', 'our', 'a', 'n’t', 'for', 'it', 'wherein', 'along', 'hereupon', 'thus', 'whose', 'besides', 'hence', 'thence', 'himself', 'have', 'much', 'enough', 'or', 'out', 'against', 'formerly', 'beside', 'from', 'thereby', 'sixty', 'regarding', 'been', 'not', 'anyone', 'why', 'fifteen', 'onto', 'just', 'ca', 'make', 'upon', 'whereby', 'same', 'him', 'made', 'now', 'did', 'but', 'afterwards', 'nor', 'everywhere', 'who', '‘m', 'too', \"'s\", 'less', 'everyone', 'when', 'last', 'all', 'any', 'beforehand', 'amount'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2rx0Xg4gRMx",
        "outputId": "0401d728-3037-4bb6-88c0-042e9361bb07"
      },
      "source": [
        "STOP_WORDS.add('ohh')\n",
        "nlp.vocab['ohh'].is_stop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN6bIUi1gj8g"
      },
      "source": [
        "#Non chunks\n",
        "\n",
        "doc15=nlp('the man playing football is a great player.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYGKjbmWhJr1",
        "outputId": "e4bd674d-0dcd-4160-b9d7-777631d7ece3"
      },
      "source": [
        "for w in doc15.noun_chunks:\n",
        "  print(w.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the man\n",
            "football\n",
            "a great player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feZ7lzgChRnN",
        "outputId": "9494555a-ffb3-4b3b-ff00-ce25cf2d5a9d"
      },
      "source": [
        "#get root words\n",
        "for w in doc15.noun_chunks:\n",
        "  print(w.root.text) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man\n",
            "football\n",
            "player\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fuvmxw8LhvDo",
        "outputId": "711cee33-f2a5-4491-ef8b-c9c838608360"
      },
      "source": [
        "for w in doc15.noun_chunks:\n",
        "    print(w.root.text,\"--connected by =\",w.root.head.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man --connected by = is\n",
            "football --connected by = playing\n",
            "player --connected by = is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO3Iu7ACizsn"
      },
      "source": [
        "## Sentence Segmentation and Boundary Detection\n",
        "\n",
        "doc25=nlp(\"Hello friends ,we are learning spaCy. Are you all enjoying? keep learning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9NRlkPvjmOe",
        "outputId": "70dda61e-76ae-484e-933e-7078cf2eb78e"
      },
      "source": [
        "for sent in doc25.sents:\n",
        "  print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello friends ,we are learning spaCy.\n",
            "Are you all enjoying?\n",
            "keep learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdgxV7Pyjt2q"
      },
      "source": [
        "doc3=nlp(\"spaCy is an amazing library\\nWe want to learn it in depth\\nThat's why we are here :P\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVU43gs4j6tX",
        "outputId": "7a1c1ebb-74e9-4b8f-86cf-60c37e4f5f76"
      },
      "source": [
        "for s in doc3.sents:\n",
        "    print(s.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy is an amazing library\n",
            "\n",
            "We want to learn it in depth\n",
            "\n",
            "That's why we are here :P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIdgUe-ij9qU",
        "outputId": "af7c9120-1605-43b0-f788-846279049f0e"
      },
      "source": [
        "for s in doc3.sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy is an amazing library\n",
            "\n",
            "We want to learn it in depth\n",
            "\n",
            "That's why we are here :P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsA2WKAQkRHo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}